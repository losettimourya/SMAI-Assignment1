{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset from the .npy file\n",
    "data = np.load('data.npy', allow_pickle=True)\n",
    "\n",
    "# Extract the labels (assuming labels are in the 4th column)\n",
    "labels = data[:, 3]\n",
    "\n",
    "# Calculate the frequency of each label using NumPy's unique function\n",
    "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# Create a bar graph to visualize the label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(unique_labels, label_counts, align='center', alpha=0.7)\n",
    "plt.xlabel('Label Name')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Label Distribution in the Dataset')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=5, distance_metric='manhattan', encoder_type=None):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.encoder_type = encoder_type\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "    def train_val_split(self,X, y, test_size=0.2, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(X))\n",
    "        split_index = int(len(X) * (1 - test_size))\n",
    "        train_indices, val_indices = indices[:split_index], indices[split_index:]\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_val]\n",
    "            \n",
    "        return x_train, x_val, y_train, y_val\n",
    "\n",
    "    def unshuffled_train_val_split(self,X,y,test_size=0.2):\n",
    "        total_samples = len(X)\n",
    "        split_index = int(total_samples * (1 - test_size))\n",
    "\n",
    "        X_train = X[:split_index]\n",
    "        X_test = X[split_index:]\n",
    "        y_train = y[:split_index]\n",
    "        y_test = y[split_index:]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_test]\n",
    "        return x_train, x_val, y_train, y_test\n",
    "    def fit(self, data):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_vit, y)\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_resnet, y)\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=2)\n",
    "    def manhattan_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=1)\n",
    "    def cosine_distance(self, x1, x2) -> float:\n",
    "        return 1-np.dot(x2,x1)/(np.linalg.norm(x2,axis=1)*np.linalg.norm(x1))\n",
    "    def calculate_distance(self, x1, x2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return self.euclidean_distance(x1, x2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return self.manhattan_distance(x1, x2)\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            return self.cosine_distance(x1, x2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "    def fitpt2(self, data, X_test):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_vit\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_resnet\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        \n",
    "    def predict(self):\n",
    "        y_pred = []\n",
    "        for x in self.X_test:\n",
    "            distances = self.calculate_distance(x, self.X_train)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            pred_label = unique_labels[np.argmax(counts)]\n",
    "            y_pred.append(pred_label)\n",
    "        print(self.encoder_type)\n",
    "        print(\"Accuracy:\" + str(accuracy_score(self.y_test,y_pred)))\n",
    "        print(\"F1 Score:\" + str(f1_score(self.y_test,y_pred,average='macro')))\n",
    "        print(\"Precision score:\" + str(precision_score(self.y_test,y_pred,average='macro',zero_division=0)))\n",
    "        print(\"Recall score:\" + str(recall_score(self.y_test,y_pred,average='macro',zero_division=0)))\n",
    "def train_val_split(X, y, test_size=0.2, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    train_indices, val_indices = indices[:split_index], indices[split_index:]\n",
    "    X_train, X_val = X[train_indices], X[val_indices]\n",
    "    y_train, y_val = y[train_indices], y[val_indices]\n",
    "    x_train = [item[0][0] for item in X_train]\n",
    "    x_val = [item[0][0] for item in X_val]\n",
    "        \n",
    "    return x_train, x_val, y_train, y_val\n",
    "data = np.load('data.npy', allow_pickle=True)\n",
    "X_vit = data[:, 2:3]\n",
    "y = data[:, 3] \n",
    "X_train, X_test, y_train, y_test = train_val_split(X_vit, y)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "start_time = time.time()\n",
    "vit_knn = KNNClassifier(k=3, distance_metric='euclidean',encoder_type='VIT')\n",
    "vit_knn.fit(data=data)\n",
    "vit_knn.predict()\n",
    "end_time = time.time()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "end2_time = time.time()\n",
    "resnet_knn = KNNClassifier(k=5, distance_metric='cosine',encoder_type='Resnet')\n",
    "resnet_knn.fit(data=data)\n",
    "resnet_knn.predict()\n",
    "execution_time = end_time - start_time\n",
    "execution_time2 = end2_time - end_time\n",
    "print(f\"Execution time1: {execution_time} seconds\")\n",
    "print(f\"Execution time2: {execution_time2} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1.1 & 2.4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=5, distance_metric='manhattan', encoder_type=None):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.encoder_type = encoder_type\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "    def train_val_split(self,X, y, test_size=0.2, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(X))\n",
    "        split_index = int(len(X) * (1 - test_size))\n",
    "        train_indices, val_indices = indices[:split_index], indices[split_index:]\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_val]\n",
    "            \n",
    "        return x_train, x_val, y_train, y_val\n",
    "\n",
    "    def unshuffled_train_val_split(self,X,y,test_size=0.2):\n",
    "        total_samples = len(X)\n",
    "        split_index = int(total_samples * (1 - test_size))\n",
    "\n",
    "        X_train = X[:split_index]\n",
    "        X_test = X[split_index:]\n",
    "        y_train = y[:split_index]\n",
    "        y_test = y[split_index:]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_test]\n",
    "        return x_train, x_val, y_train, y_test\n",
    "    def fit(self, data):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_vit, y)\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_resnet, y)\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        # return np.sqrt(np.sum((x1 - x2) ** 2),axis=1)\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=2)\n",
    "\n",
    "    def manhattan_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=1)\n",
    "\n",
    "    def cosine_distance(self, x1, x2):\n",
    "        return 1-np.dot(x2,x1)/(np.linalg.norm(x2,axis=1)*np.linalg.norm(x1))\n",
    "\n",
    "    def calculate_distance(self, x1, x2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return self.euclidean_distance(x1, x2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return self.manhattan_distance(x1, x2)\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            return self.cosine_distance(x1, x2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "    def fitpt2(self, data, X_test):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_vit\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_resnet\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        \n",
    "    def predict(self):\n",
    "        y_pred = []\n",
    "        for x in self.X_test:\n",
    "            distances = self.calculate_distance(x, self.X_train)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            pred_label = unique_labels[np.argmax(counts)]\n",
    "            y_pred.append(pred_label)\n",
    "        return accuracy_score(self.y_test,y_pred)\n",
    "    \n",
    "data = np.load('data.npy', allow_pickle=True)\n",
    "k_value = []\n",
    "accuracy = []\n",
    "answer = []\n",
    "for i in ['VIT', 'Resnet']:\n",
    "    for j in ['manhattan', 'euclidean', 'cosine']:\n",
    "        for kk in range(1,10,2):\n",
    "            knn = KNNClassifier(k=kk,distance_metric=j,encoder_type=i)\n",
    "            knn.fit(data=data)\n",
    "            ans = knn.predict()\n",
    "            answer.append([ans,kk,j,i])\n",
    "            k_value.append(i)\n",
    "            accuracy.append(ans)\n",
    "answer.sort(reverse=True)\n",
    "print(\"The best triplet is: \")\n",
    "print(\"K = \" + str(answer[0][1]))\n",
    "print(\"Distance metric = \" + str(answer[0][2]))\n",
    "print(\"Encoder type: \" + str(answer[0][3]))\n",
    "j=0\n",
    "print()\n",
    "print(\"The top 20 triplets are: \")\n",
    "for i in answer:\n",
    "    print(i)\n",
    "    j += 1\n",
    "    if(j == 20):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=5, distance_metric='manhattan', encoder_type=None):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.encoder_type = encoder_type\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "    def train_val_split(self,X, y, test_size=0.2, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(X))\n",
    "        split_index = int(len(X) * (1 - test_size))\n",
    "        train_indices, val_indices = indices[:split_index], indices[split_index:]\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_val]\n",
    "            \n",
    "        return x_train, x_val, y_train, y_val\n",
    "\n",
    "    def unshuffled_train_val_split(self,X,y,test_size=0.2):\n",
    "        total_samples = len(X)\n",
    "        split_index = int(total_samples * (1 - test_size))\n",
    "\n",
    "        X_train = X[:split_index]\n",
    "        X_test = X[split_index:]\n",
    "        y_train = y[:split_index]\n",
    "        y_test = y[split_index:]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_test]\n",
    "        return x_train, x_val, y_train, y_test\n",
    "    def fit(self, data):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_vit, y)\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_resnet, y)\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        # return np.sqrt(np.sum((x1 - x2) ** 2),axis=1)\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=2)\n",
    "\n",
    "    def manhattan_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=1)\n",
    "\n",
    "    def cosine_distance(self, x1, x2):\n",
    "        return 1-np.dot(x2,x1)/(np.linalg.norm(x2,axis=1)*np.linalg.norm(x1))\n",
    "\n",
    "    def calculate_distance(self, x1, x2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return self.euclidean_distance(x1, x2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return self.manhattan_distance(x1, x2)\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            return self.cosine_distance(x1, x2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "    def fitpt2(self, data, X_test):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_vit\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_resnet\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        \n",
    "    def predict(self):\n",
    "        y_pred = []\n",
    "        #print(len(X_test[0][0]))\n",
    "        #print(X_test)\n",
    "        for x in self.X_test:\n",
    "            #print(x)\n",
    "            #distances = [self.calculate_distance(x[0][0], x_train[0][0]) for x_train in self.X_train]\n",
    "            #self.X_train = self.X_train[0]\n",
    "            # print(len(self.X_train))\n",
    "            # print(len(x[0][0]))\n",
    "            distances = self.calculate_distance(x, self.X_train)\n",
    "            # distances = np.array([self.calculate_distance(x[0][0], x_train[0][0]) for x_train in self.X_train])\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            pred_label = unique_labels[np.argmax(counts)]\n",
    "            y_pred.append(pred_label)\n",
    "        return accuracy_score(self.y_test,y_pred)\n",
    "        #return np.array(y_pred)\n",
    "\n",
    "# Load the dataset from data.npy\n",
    "data = np.load('data.npy', allow_pickle=True)\n",
    "# X_resnet = data[:, 1:2] \n",
    "# X_vit = data[:, 2:3]\n",
    "# y = data[:, 3] \n",
    "    \n",
    "\n",
    "# X_resnet_train, X_resnet_test, y_resnet_train, y_resnet_test = train_val_split(X_resnet, y)\n",
    "# X_vit_train, X_vit_test, y_vit_train, y_vit_test = train_val_split(X_vit, y)\n",
    "k_value = []\n",
    "accuracy = []\n",
    "for i in range(1,10,2):\n",
    "    knn = KNNClassifier(k=i,distance_metric='euclidean',encoder_type='VIT')\n",
    "    knn.fit(data=data)\n",
    "    ans = knn.predict()\n",
    "    k_value.append(i)\n",
    "    accuracy.append(ans)\n",
    "\n",
    "print(k_value)\n",
    "print(accuracy)\n",
    "plt.plot(k_value, accuracy, marker='o', linestyle='-')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('K vs Accuracy graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=5, distance_metric='manhattan', encoder_type=None):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.encoder_type = encoder_type\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "    def train_val_split(self,X, y, test_size=0.2, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(X))\n",
    "        split_index = int(len(X) * (1 - test_size))\n",
    "        train_indices, val_indices = indices[:split_index], indices[split_index:]\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_val]\n",
    "            \n",
    "        return x_train, x_val, y_train, y_val\n",
    "\n",
    "    def unshuffled_train_val_split(self,X,y,test_size=0.2):\n",
    "        total_samples = len(X)\n",
    "        split_index = int(total_samples * (1 - test_size))\n",
    "\n",
    "        X_train = X[:split_index]\n",
    "        X_test = X[split_index:]\n",
    "        y_train = y[:split_index]\n",
    "        y_test = y[split_index:]\n",
    "        x_train = [item[0][0] for item in X_train]\n",
    "        x_val = [item[0][0] for item in X_test]\n",
    "        return x_train, x_val, y_train, y_test\n",
    "    def fit(self, data):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_vit, y)\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.train_val_split(X_resnet, y)\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=2)\n",
    "    def manhattan_distance(self, x1, x2):\n",
    "        return np.linalg.norm(x1-x2,axis=1,ord=1)\n",
    "    def cosine_distance(self, x1, x2) -> float:\n",
    "        return 1-np.dot(x2,x1)/(np.linalg.norm(x2,axis=1)*np.linalg.norm(x1))\n",
    "    def calculate_distance(self, x1, x2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return self.euclidean_distance(x1, x2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return self.manhattan_distance(x1, x2)\n",
    "        elif self.distance_metric == 'cosine':\n",
    "            return self.cosine_distance(x1, x2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "    def fitpt2(self, data, X_test):\n",
    "        if self.encoder_type == 'VIT':\n",
    "            X_vit = data[:, 2:3]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_vit\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        elif self.encoder_type == 'Resnet':\n",
    "            X_resnet = data[:, 1:2]\n",
    "            y = data[:, 3] \n",
    "            self.X_train = X_resnet\n",
    "            self.y_train = y\n",
    "            self.X_test = X_test\n",
    "        \n",
    "    def predict(self):\n",
    "        y_pred = []\n",
    "        for x in self.X_test:\n",
    "            distances = self.calculate_distance(x, self.X_train)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            pred_label = unique_labels[np.argmax(counts)]\n",
    "            y_pred.append(pred_label)\n",
    "def train_val_split(X, y, test_size=0.2, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    train_indices, val_indices = indices[:split_index], indices[split_index:]\n",
    "    X_train, X_val = X[train_indices], X[val_indices]\n",
    "    y_train, y_val = y[train_indices], y[val_indices]\n",
    "    x_train = [item[0][0] for item in X_train]\n",
    "    x_val = [item[0][0] for item in X_val]\n",
    "        \n",
    "    return x_train, x_val, y_train, y_val\n",
    "data = np.load('data.npy', allow_pickle=True)\n",
    "X_vit = data[:, 2:3]\n",
    "y = data[:, 3] \n",
    "X_train, X_test, y_train, y_test = train_val_split(X_vit, y)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "start_time = time.time()\n",
    "vit_knn = KNNClassifier(k=3, distance_metric='manhattan',encoder_type='VIT')\n",
    "vit_knn.fit(data=data)\n",
    "vit_knn.predict()\n",
    "end_time = time.time()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "end2_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "execution_time2 = end2_time - end_time\n",
    "# print(f\"Execution time1: {execution_time} seconds\")\n",
    "# print(f\"Execution time2: {execution_time2} seconds\")\n",
    "data = {\n",
    "    'Most Optimized KNN': execution_time,\n",
    "    'Sklearn KNN': execution_time2\n",
    "}\n",
    "labels = list(data.keys())\n",
    "values = list(data.values())\n",
    "plt.bar(labels, values, color=['blue', 'green'])\n",
    "plt.xlabel('KNN Algorithm')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Comparison of Execution Time between Most Optimized KNN and Sklearn KNN')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 (MultiOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class MultiOutputDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, max_features='auto', criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.classifier = DecisionTreeClassifier(criterion=criterion,random_state=42)\n",
    "    def fit(self, X, y):\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        y = mlb.fit_transform(y.str.split(' '))\n",
    "        self.classifier.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "data = pd.read_csv('advertisement.csv')  # Replace with your CSV file path\n",
    "print(\"Original DataFrame:\")\n",
    "print(data.head())\n",
    "data.fillna(method='ffill', inplace=True) \n",
    "categorical_cols = ['gender', 'education', 'married', 'city', 'occupation', 'most bought item']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "print(\"Encoded DataFrame:\")\n",
    "print(data_encoded.head())\n",
    "X = data_encoded.drop('labels', axis=1)  # Features\n",
    "y = data_encoded['labels']  # Target variable\n",
    "print(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y_train)\n",
    "mlb = MultiLabelBinarizer()\n",
    "# y_train = y_train.str.get_dummies(sep=' ')\n",
    "# y_train = mlb.fit_transform(y_train)\n",
    "y_val = mlb.fit_transform(y_val.str.split(' '))\n",
    "# y_val = y_val.str.get_dummies(sep=' ')\n",
    "# print(y_train)\n",
    "print(y_val)\n",
    "clf = MultiOutputDecisionTreeClassifier(max_depth=5, max_features = 5,criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "print(val_predictions)\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "micro_f1 = f1_score(y_val, val_predictions, average='micro')\n",
    "macro_f1 = f1_score(y_val, val_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val.argmax(axis=1), val_predictions.argmax(axis=1))\n",
    "precision = precision_score(y_val, val_predictions, average='micro')\n",
    "recall = recall_score(y_val, val_predictions, average='micro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 (Micro): {micro_f1:.2f}')\n",
    "print(f'F1 (Macro): {macro_f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print(f'Precision (Micro): {precision:.2f}')\n",
    "print(f'Recall (Micro): {recall:.2f}')\n",
    "# val_predictions = mlb.inverse_transform(val_predictions)\n",
    "# y_val = mlb.inverse_transform(y_val)\n",
    "\n",
    "# Initialize an empty dictionary to store confusion matrices for each label\n",
    "# confusion_matrices = {}\n",
    "\n",
    "# # Compute confusion matrix for each label\n",
    "# for label_idx, label in enumerate(mlb.classes_):\n",
    "#     y_val_label = [1 if label in labels else 0 for labels in y_val]\n",
    "#     val_predictions_label = [1 if label in labels else 0 for labels in val_predictions]\n",
    "#     cm = confusion_matrix(y_val_label, val_predictions_label)\n",
    "#     confusion_matrices[label] = cm\n",
    "\n",
    "# # Print confusion matrices for each label\n",
    "# for label, cm in confusion_matrices.items():\n",
    "#     print(f'Confusion Matrix for Label \"{label}\":')\n",
    "#     print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 (Powerset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class PowersetDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, max_features='auto', criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.classifier = DecisionTreeClassifier(max_depth=max_depth,max_features=max_features,criterion=criterion,random_state=42)\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "data = pd.read_csv('advertisement.csv')  # Replace with your CSV file path\n",
    "# print(\"Original DataFrame:\")\n",
    "# print(data.head())\n",
    "data.fillna(method='ffill', inplace=True) \n",
    "categorical_cols = ['gender', 'education', 'married', 'city', 'occupation', 'most bought item']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "# print(\"Encoded DataFrame:\")\n",
    "# print(data_encoded.head())\n",
    "X = data_encoded.drop('labels', axis=1)  # Features\n",
    "y = data_encoded['labels']  # Target variable\n",
    "# print(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# print(y_train)\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    unique_combos = set()\n",
    "    for r in range(0,len(s) + 1):\n",
    "        for combo in combinations(sorted(s), r):\n",
    "            # return tuple(combo)\n",
    "            unique_combos.add(tuple(combo))\n",
    "    return list(unique_combos)\n",
    "label_combinations = y_train.apply(lambda x: tuple(x.split(' '))).apply(powerset)\n",
    "label_combinations_val = y_val.apply(lambda x: tuple(x.split(' '))).apply(powerset)\n",
    "print(label_combinations)\n",
    "unique_labels = y.str.split(' ').explode().unique()  \n",
    "all_labels = list(chain.from_iterable(combinations(unique_labels, r) for r in range(len(unique_labels) + 1)))\n",
    "all_label_combinations = all_labels\n",
    "#print(label_combinations_val)\n",
    "# all_label_combinations = list(set(label_combinations.sum() + label_combinations_val.sum()))\n",
    "# print(all_label_combinations)\n",
    "print(label_combinations_val)\n",
    "label_combinations_list = label_combinations.tolist()\n",
    "label_combinations_val_list = label_combinations_val.tolist()\n",
    "print(label_combinations_val_list)\n",
    "#print(label_combinations_list)\n",
    "mlb = MultiLabelBinarizer(classes=all_label_combinations)\n",
    "y_train = mlb.fit_transform(label_combinations_list)\n",
    "y_train_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "y_train = y_train_df.loc[:, ~y_train_df.columns.duplicated()]\n",
    "y_val = mlb.fit_transform(label_combinations_val_list)\n",
    "y_val_df = pd.DataFrame(y_val, columns=mlb.classes_)\n",
    "# # Remove duplicate columns, if any\n",
    "y_val = y_val_df.loc[:, ~y_val_df.columns.duplicated()]\n",
    "# # y_val = mlb.fit_transform(y_val.apply(lambda x: tuple(x.split(' '))))\n",
    "#print(y_train)\n",
    "print(y_val)\n",
    "clf = PowersetDecisionTreeClassifier(max_depth=30, max_features = 11,criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "val_predictions = clf.predict(X_val)\n",
    "# print(val_predictions)\n",
    "y_val = y_val.to_numpy()\n",
    "print(np.sum(y_val[0]))\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "micro_f1 = f1_score(y_val, val_predictions, average='micro')\n",
    "macro_f1 = f1_score(y_val, val_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(y_val.argmax(axis=1), val_predictions.argmax(axis=1))\n",
    "precision = precision_score(y_val, val_predictions, average='micro')\n",
    "recall = recall_score(y_val, val_predictions, average='micro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'F1 (Micro): {micro_f1:.5f}')\n",
    "print(f'F1 (Macro): {macro_f1:.5f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print(f'Precision (Micro): {precision:.5f}')\n",
    "print(f'Recall (Micro): {recall:.5f}')\n",
    "# val_predictions = mlb.inverse_transform(val_predictions)\n",
    "# y_val = mlb.inverse_transform(y_val)\n",
    "\n",
    "# Initialize an empty dictionary to store confusion matrices for each label\n",
    "# confusion_matrices = {}\n",
    "\n",
    "# # Compute confusion matrix for each label\n",
    "# for label_idx, label in enumerate(mlb.classes_):\n",
    "#     y_val_label = [1 if label in labels else 0 for labels in y_val]\n",
    "#     val_predictions_label = [1 if label in labels else 0 for labels in val_predictions]\n",
    "#     cm = confusion_matrix(y_val_label, val_predictions_label)\n",
    "#     confusion_matrices[label] = cm\n",
    "\n",
    "# # Print confusion matrices for each label\n",
    "# for label, cm in confusion_matrices.items():\n",
    "#     print(f'Confusion Matrix for Label \"{label}\":')\n",
    "#     print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1.1 (MultiOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class MultiOutputDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, max_features='auto', criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.classifier = DecisionTreeClassifier(max_depth=max_depth,max_features=max_features,criterion=criterion,random_state=42)\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "data = pd.read_csv('advertisement.csv')  # Replace with your CSV file path\n",
    "print(\"Original DataFrame:\")\n",
    "print(data.head())\n",
    "data.fillna(method='ffill', inplace=True) \n",
    "categorical_cols = ['gender', 'education', 'married', 'city', 'occupation', 'most bought item']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "print(\"Encoded DataFrame:\")\n",
    "print(data_encoded.head())\n",
    "X = data_encoded.drop('labels', axis=1)  # Features\n",
    "y = data_encoded['labels']  # Target variable\n",
    "print(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y_train)\n",
    "mlb = MultiLabelBinarizer()\n",
    "# y_train = y_train.str.get_dummies(sep=' ')\n",
    "y_train = mlb.fit_transform(y_train.str.split(' '))\n",
    "y_val = mlb.fit_transform(y_val.str.split(' '))\n",
    "# y_val = y_val.str.get_dummies(sep=' ')\n",
    "# print(y_train)\n",
    "# print(y_val)\n",
    "for i in [3,5,10,20,30]:\n",
    "    for j in [3,5,7,9,11]:\n",
    "        for k in ['gini','entropy']:            \n",
    "            clf = MultiOutputDecisionTreeClassifier(max_depth=i, max_features = j,criterion=k)\n",
    "            clf.fit(X_train, y_train)\n",
    "            val_predictions = clf.predict(X_val)\n",
    "            # print(val_predictions)\n",
    "            accuracy = accuracy_score(y_val, val_predictions)\n",
    "            micro_f1 = f1_score(y_val, val_predictions, average='micro',zero_division=0)\n",
    "            macro_f1 = f1_score(y_val, val_predictions, average='macro',zero_division=0)\n",
    "            conf_matrix = confusion_matrix(y_val.argmax(axis=1), val_predictions.argmax(axis=1))\n",
    "            precision = precision_score(y_val, val_predictions, average='micro')\n",
    "            recall = recall_score(y_val, val_predictions, average='micro')\n",
    "            print(\"Max Depth: \" + str(i) + \" Max Features: \" + str(j) + \" Criterion: \" + str(k))\n",
    "            print(f'Accuracy: {accuracy:.2f}')\n",
    "            print(f'F1 (Micro): {micro_f1:.2f}')\n",
    "            print(f'F1 (Macro): {macro_f1:.2f}')\n",
    "            print('Confusion Matrix:')\n",
    "            print(conf_matrix)\n",
    "            print(f'Precision (Micro): {precision:.2f}')\n",
    "            print(f'Recall (Micro): {recall:.2f}')\n",
    "# val_predictions = mlb.inverse_transform(val_predictions)\n",
    "# y_val = mlb.inverse_transform(y_val)\n",
    "\n",
    "# Initialize an empty dictionary to store confusion matrices for each label\n",
    "# confusion_matrices = {}\n",
    "\n",
    "# # Compute confusion matrix for each label\n",
    "# for label_idx, label in enumerate(mlb.classes_):\n",
    "#     y_val_label = [1 if label in labels else 0 for labels in y_val]\n",
    "#     val_predictions_label = [1 if label in labels else 0 for labels in val_predictions]\n",
    "#     cm = confusion_matrix(y_val_label, val_predictions_label)\n",
    "#     confusion_matrices[label] = cm\n",
    "\n",
    "# # Print confusion matrices for each label\n",
    "# for label, cm in confusion_matrices.items():\n",
    "#     print(f'Confusion Matrix for Label \"{label}\":')\n",
    "#     print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1.1 (Powerset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class PowersetDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, max_features='auto', criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.classifier = DecisionTreeClassifier(max_depth = max_depth, max_features=max_features,criterion=criterion,random_state=42)\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "data = pd.read_csv('advertisement.csv')  # Replace with your CSV file path\n",
    "# print(\"Original DataFrame:\")\n",
    "# print(data.head())\n",
    "data.fillna(method='ffill', inplace=True) \n",
    "categorical_cols = ['gender', 'education', 'married', 'city', 'occupation', 'most bought item']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "# print(\"Encoded DataFrame:\")\n",
    "# print(data_encoded.head())\n",
    "X = data_encoded.drop('labels', axis=1)  # Features\n",
    "y = data_encoded['labels']  # Target variable\n",
    "# print(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# print(y_train)\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    unique_combos = set()\n",
    "    for r in range(len(s),len(s) + 1):\n",
    "        for combo in combinations(sorted(s), r):\n",
    "            return tuple(combo)\n",
    "            unique_combos.add(tuple(combo))\n",
    "    return list(unique_combos)\n",
    "label_combinations = y_train.apply(lambda x: tuple(x.split(' '))).apply(powerset)\n",
    "label_combinations_val = y_val.apply(lambda x: tuple(x.split(' '))).apply(powerset)\n",
    "# print(label_combinations)\n",
    "\n",
    "all_label_combinations = list(set(label_combinations.sum() + label_combinations_val.sum()))\n",
    "unique_labels = y.str.split(' ').explode().unique()  \n",
    "all_label_combinations = list(chain.from_iterable(combinations(unique_labels, r) for r in range(len(unique_labels) + 1)))\n",
    "label_combinations_list = label_combinations.tolist()\n",
    "label_combinations_val_list = label_combinations_val.tolist()\n",
    "#print(label_combinations_list)\n",
    "print(label_combinations_val_list)\n",
    "all_label_combinations = sorted(all_label_combinations, key=lambda x: tuple(sorted(x)))\n",
    "mlb = MultiLabelBinarizer(classes=np.arange(len(all_label_combinations)))\n",
    "mlb.fit(all_label_combinations)\n",
    "def custom_binarize(label_combination):\n",
    "    binarized = np.zeros(len(all_label_combinations))\n",
    "    for idx, label_set in enumerate(all_label_combinations):\n",
    "        if set(label_set) == set(label_combination):\n",
    "            binarized[idx] = 1\n",
    "    return binarized\n",
    "\n",
    "# Binarize y_train and y_val using the custom binarization function\n",
    "print(y_val)\n",
    "y_train = np.array([custom_binarize(labels) for labels in label_combinations_list])\n",
    "y_val = np.array([custom_binarize(labels) for labels in label_combinations_val_list])\n",
    "# y_train = mlb.fit_transform(label_combinations_list)\n",
    "# y_train_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "# y_train = y_train_df.loc[:, ~y_train_df.columns.duplicated()]\n",
    "# y_val = mlb.fit_transform(label_combinations_val_list)\n",
    "# y_val_df = pd.DataFrame(y_val, columns=mlb.classes_)\n",
    "# # # Remove duplicate columns, if any\n",
    "# y_val = y_val_df.loc[:, ~y_val_df.columns.duplicated()]\n",
    "# # y_val = mlb.fit_transform(y_val.apply(lambda x: tuple(x.split(' '))))\n",
    "#print(y_train)\n",
    "# print(y_val)\n",
    "# print(np.sum(y_val[1]))\n",
    "for i in [3,5,10,20,30]:\n",
    "    for j in [3,5,7,9,11]:\n",
    "            for k in ['gini','entropy']:  \n",
    "                clf = PowersetDecisionTreeClassifier(max_depth=i, max_features = j,criterion=k)\n",
    "                clf.fit(X_train, y_train)\n",
    "                val_predictions = clf.predict(X_val)\n",
    "                # print(val_predictions)\n",
    "                # y_val = y_val.to_numpy()\n",
    "                # print(np.sum(y_val[0]))\n",
    "                # print(val_predictions)\n",
    "                accuracy = accuracy_score(y_val, val_predictions)\n",
    "                micro_f1 = f1_score(y_val, val_predictions, average='micro',zero_division=0)\n",
    "                macro_f1 = f1_score(y_val, val_predictions, average='macro',zero_division=0)\n",
    "                conf_matrix = confusion_matrix(y_val.argmax(axis=1), val_predictions.argmax(axis=1))\n",
    "                precision = precision_score(y_val, val_predictions, average='micro',zero_division=0)\n",
    "                recall = recall_score(y_val, val_predictions, average='micro',zero_division=0)\n",
    "                print(\"Max Depth: \" + str(i) + \" Max Features: \" + str(j) + \" Criterion: \" + str(k))\n",
    "                print(f'Accuracy: {accuracy:.5f}')\n",
    "                print(f'F1 (Micro): {micro_f1:.5f}')\n",
    "                print(f'F1 (Macro): {macro_f1:.5f}')\n",
    "                print('Confusion Matrix:')\n",
    "                print(conf_matrix)\n",
    "                print(f'Precision (Micro): {precision:.5f}')\n",
    "                print(f'Recall (Micro): {recall:.5f}')\n",
    "# val_predictions = mlb.inverse_transform(val_predictions)\n",
    "# y_val = mlb.inverse_transform(y_val)\n",
    "\n",
    "# Initialize an empty dictionary to store confusion matrices for each label\n",
    "# confusion_matrices = {}\n",
    "\n",
    "# # Compute confusion matrix for each label\n",
    "# for label_idx, label in enumerate(mlb.classes_):\n",
    "#     y_val_label = [1 if label in labels else 0 for labels in y_val]\n",
    "#     val_predictions_label = [1 if label in labels else 0 for labels in val_predictions]\n",
    "#     cm = confusion_matrix(y_val_label, val_predictions_label)\n",
    "#     confusion_matrices[label] = cm\n",
    "\n",
    "# # Print confusion matrices for each label\n",
    "# for label, cm in confusion_matrices.items():\n",
    "#     print(f'Confusion Matrix for Label \"{label}\":')\n",
    "#     print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1.2 (MultiOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class MultiOutputDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth, max_features, criterion):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.classifier = DecisionTreeClassifier(max_depth=max_depth, max_features = max_features,criterion=criterion,random_state=42)\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "data = pd.read_csv('advertisement.csv') \n",
    "data.fillna(method='ffill', inplace=True) \n",
    "categorical_cols = ['gender', 'education', 'married', 'city', 'occupation', 'most bought item']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "X = data_encoded.drop('labels', axis=1) \n",
    "y = data_encoded['labels'] \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "# test_size = 0.2\n",
    "\n",
    "# # Calculate the number of data points to reserve for testing\n",
    "# num_test_samples = int(len(X) * test_size)\n",
    "\n",
    "# # Create the training and testing sets without shuffling\n",
    "# X_train, X_val = X[:num_test_samples], X[num_test_samples:]\n",
    "# y_train, y_val = y[:num_test_samples], y[num_test_samples:]\n",
    "mlb = MultiLabelBinarizer()\n",
    "# y_train = y_train.str.get_dummies(sep=' ')\n",
    "y_train = mlb.fit_transform(y_train.str.split(' '))\n",
    "y_val = mlb.fit_transform(y_val.str.split(' '))\n",
    "print(y_train[1])\n",
    "ans = []\n",
    "for i in [3,5,10,20,30]:\n",
    "    for j in [3,5,7,9,11]:\n",
    "        for k in ['gini','entropy']:\n",
    "            clf = MultiOutputDecisionTreeClassifier(max_depth=i, max_features = j,criterion=k)\n",
    "            clf.fit(X_train, y_train)\n",
    "            val_predictions = clf.predict(X_val)\n",
    "            # print(y_val)\n",
    "            macro_f1 = f1_score(y_val, val_predictions, average='macro')\n",
    "            ans.append([macro_f1,i,j,k])\n",
    "ans.sort(reverse=True)\n",
    "for i in range(0,3):\n",
    "    print(\"F1 Score: \" + str(ans[i][0]) + \" Max Depth: \" + str(ans[i][1]) + \" Max Features: \" + str(ans[i][2]) + \" Criterion: \" + str(ans[i][3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1.2 (Powerset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class PowersetDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, max_features='auto', criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.criterion = criterion\n",
    "        self.classifier = DecisionTreeClassifier(max_depth = max_depth, max_features=max_features,criterion=criterion,random_state=42)\n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "data = pd.read_csv('advertisement.csv') \n",
    "data.fillna(method='ffill', inplace=True) \n",
    "categorical_cols = ['gender', 'education', 'married', 'city', 'occupation', 'most bought item']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "X = data_encoded.drop('labels', axis=1)  \n",
    "y = data_encoded['labels']  \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    unique_combos = set()\n",
    "    for r in range(len(s),len(s) + 1):\n",
    "        for combo in combinations(sorted(s), r):\n",
    "            return tuple(combo)\n",
    "            unique_combos.add(tuple(combo))\n",
    "    return list(unique_combos)\n",
    "label_combinations = y_train.apply(lambda x: tuple(x.split(' '))).apply(powerset)\n",
    "label_combinations_val = y_val.apply(lambda x: tuple(x.split(' '))).apply(powerset)\n",
    "all_label_combinations = list(set(label_combinations.sum() + label_combinations_val.sum()))\n",
    "unique_labels = y.str.split(' ').explode().unique()  \n",
    "all_label_combinations = list(chain.from_iterable(combinations(unique_labels, r) for r in range(len(unique_labels) + 1)))\n",
    "label_combinations_list = label_combinations.tolist()\n",
    "label_combinations_val_list = label_combinations_val.tolist()\n",
    "all_label_combinations = sorted(all_label_combinations, key=lambda x: tuple(sorted(x)))\n",
    "mlb = MultiLabelBinarizer(classes=np.arange(len(all_label_combinations)))\n",
    "mlb.fit(all_label_combinations)\n",
    "def custom_binarize(label_combination):\n",
    "    binarized = np.zeros(len(all_label_combinations))\n",
    "    for idx, label_set in enumerate(all_label_combinations):\n",
    "        if set(label_set) == set(label_combination):\n",
    "            binarized[idx] = 1\n",
    "    return binarized\n",
    "\n",
    "# Binarize y_train and y_val using the custom binarization function\n",
    "print(label_combinations_list[0])\n",
    "print(label_combinations_val_list[0])\n",
    "y_train = np.array([custom_binarize(labels) for labels in label_combinations_list])\n",
    "y_val = np.array([custom_binarize(labels) for labels in label_combinations_val_list])\n",
    "# print(np.sum(y_train[0])\n",
    "# )\n",
    "# y_train = mlb.fit_transform(label_combinations_list)\n",
    "# y_train_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "# y_train = y_train_df.loc[:, ~y_train_df.columns.duplicated()]\n",
    "# y_val = mlb.fit_transform(label_combinations_val_list)\n",
    "# y_val_df = pd.DataFrame(y_val, columns=mlb.classes_)\n",
    "# # # Remove duplicate columns, if any\n",
    "# y_val = y_val_df.loc[:, ~y_val_df.columns.duplicated()]\n",
    "# # y_val = mlb.fit_transform(y_val.apply(lambda x: tuple(x.split(' '))))\n",
    "#print(y_train)\n",
    "# print(y_val)\n",
    "# print(np.sum(y_val[1]))\n",
    "ans = []\n",
    "for i in [3,5,10,20,30]:\n",
    "    for j in [3,5,7,9,11]:\n",
    "            for k in ['gini','entropy']:  \n",
    "                clf = PowersetDecisionTreeClassifier(max_depth=i, max_features = j,criterion=k)\n",
    "                clf.fit(X_train, y_train)\n",
    "                val_predictions = clf.predict(X_val)\n",
    "                # sum = 0\n",
    "                # for i in range(len(val_predictions)):\n",
    "                #     sum = sum + np.sum(val_predictions[i])\n",
    "                # print(sum)\n",
    "                # y_val = y_val.to_numpy()\n",
    "                # print(np.sum(y_val[0]))\n",
    "                # print(val_predictions)\n",
    "                micro_f1 = f1_score(y_val, val_predictions, average='micro', zero_division=0)\n",
    "                macro_f1 = f1_score(y_val, val_predictions, average='macro',zero_division=0)\n",
    "                ans.append([macro_f1,i,j,k,val_predictions])\n",
    "ans.sort(reverse=True)\n",
    "for i in range(0,3):\n",
    "    print(np.sum(ans[i][4]))\n",
    "    print(\"F1 Score: \" + str(ans[i][0]) + \" Max Depth: \" + str(ans[i][1]) + \" Max Features: \" + str(ans[i][2]) + \" Criterion: \" + str(ans[i][3]))\n",
    "# val_predictions = mlb.inverse_transform(val_predictions)\n",
    "# y_val = mlb.inverse_transform(y_val)\n",
    "\n",
    "# Initialize an empty dictionary to store confusion matrices for each label\n",
    "# confusion_matrices = {}\n",
    "\n",
    "# # Compute confusion matrix for each label\n",
    "# for label_idx, label in enumerate(mlb.classes_):\n",
    "#     y_val_label = [1 if label in labels else 0 for labels in y_val]\n",
    "#     val_predictions_label = [1 if label in labels else 0 for labels in val_predictions]\n",
    "#     cm = confusion_matrix(y_val_label, val_predictions_label)\n",
    "#     confusion_matrices[label] = cm\n",
    "\n",
    "# # Print confusion matrices for each label\n",
    "# for label, cm in confusion_matrices.items():\n",
    "#     print(f'Confusion Matrix for Label \"{label}\":')\n",
    "#     print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
